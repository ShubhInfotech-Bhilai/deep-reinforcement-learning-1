{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twin Delayed Deep Deterministic Policy Gradients.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sourcecode369/deep-reinforcementlearning/blob/master/TD3/Twin_Delayed_Deep_Deterministic_Policy_Gradients.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1KRkwmfn7Ox",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-Akb9bzn-Sg",
        "colab_type": "code",
        "outputId": "65d7bb5b-8d8e-459d-99d2-16f14cd88805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        }
      },
      "source": [
        "!pip install git+https://github.com/benelot/pybullet-gym.git\n",
        "!pip install tensorboardX\n",
        "!pip install gym\n",
        "#!pip install roboschool\n",
        "#!pip install pybullet"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/benelot/pybullet-gym.git\n",
            "  Cloning https://github.com/benelot/pybullet-gym.git to /tmp/pip-req-build-a876zo_5\n",
            "  Running command git clone -q https://github.com/benelot/pybullet-gym.git /tmp/pip-req-build-a876zo_5\n",
            "Collecting pybullet>=1.7.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/1c/26640b59ab18deb59104ed03ee4c26d1d998076cdf4a89c5ef1486831172/pybullet-2.6.1.tar.gz (82.8MB)\n",
            "\u001b[K     |████████████████████████████████| 82.8MB 36kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pybulletgym, pybullet\n",
            "  Building wheel for pybulletgym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybulletgym: filename=pybulletgym-0.1-cp36-none-any.whl size=1513918 sha256=bf1edf6f5f13421d15122b38b1ee202a7c650c51e8d861d1ec4ccf618e5ccca6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-99tjs2wj/wheels/ea/34/2e/1a4b77e473ea01bc931d1863c73abf7e4d1cc703904d7c74ea\n",
            "  Building wheel for pybullet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybullet: filename=pybullet-2.6.1-cp36-cp36m-linux_x86_64.whl size=94540402 sha256=afd5b2d31cb50bc2de770143574b04857972e336cfa30f4b523f13e78bf884c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/85/95/de15ebf350270f905e8ac5b060e9668642ff251d3a3e7f65ad\n",
            "Successfully built pybulletgym pybullet\n",
            "Installing collected packages: pybullet, pybulletgym\n",
            "Successfully installed pybullet-2.6.1 pybulletgym-0.1\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (1.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.17.4)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (42.0.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.15.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.17.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.3)\n",
            "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.2)\n",
            "Requirement already satisfied: cloudpickle~=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from gym) (4.1.2.30)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma5F4MOknpVM",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHXuB5zQnpVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "import gym\n",
        "import pybulletgym\n",
        "#import roboschool\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0E0YxDFic_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "if not os.path.exists('saves'):\n",
        "  os.mkdir('saves')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0He4LCpnpVT",
        "colab_type": "text"
      },
      "source": [
        "# Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP-7T-TRnpVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hidden_init(layer):\n",
        "    fan_in = layer.weight.data.size()[0]\n",
        "    lim = 1. / np.sqrt(fan_in)\n",
        "    return (-lim, lim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmpmK3D4npVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Actor(nn.Module):\n",
        "    \"\"\"Initialize parameters and build model.\n",
        "        Args:\n",
        "            state_size (int): Dimension of each state\n",
        "            action_size (int): Dimension of each action\n",
        "            max_action (float): highest action to take\n",
        "            seed (int): Random seed\n",
        "            h1_units (int): Number of nodes in first hidden layer\n",
        "            h2_units (int): Number of nodes in second hidden layer\n",
        "            \n",
        "        Return:\n",
        "            action output of network with tanh activation\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, state_dim, action_dim, max_action):\n",
        "        super(Actor, self).__init__()\n",
        "\n",
        "        self.l1 = nn.Linear(state_dim, 400)\n",
        "        self.l2 = nn.Linear(400, 300)\n",
        "        self.l3 = nn.Linear(300, action_dim)\n",
        "\n",
        "        self.max_action = max_action\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.l1(x))\n",
        "        x = F.relu(self.l2(x))\n",
        "        x = self.max_action * torch.tanh(self.l3(x)) \n",
        "        return x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yGoEuJlnpVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Critic(nn.Module):\n",
        "    \"\"\"Initialize parameters and build model.\n",
        "        Args:\n",
        "            state_size (int): Dimension of each state\n",
        "            action_size (int): Dimension of each action\n",
        "            max_action (float): highest action to take\n",
        "            seed (int): Random seed\n",
        "            h1_units (int): Number of nodes in first hidden layer\n",
        "            h2_units (int): Number of nodes in second hidden layer\n",
        "            \n",
        "        Return:\n",
        "            value output of network \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        super(Critic, self).__init__()\n",
        "\n",
        "        # Q1 architecture\n",
        "        self.l1 = nn.Linear(state_dim + action_dim, 400)\n",
        "        self.l2 = nn.Linear(400, 300)\n",
        "        self.l3 = nn.Linear(300, 1)\n",
        "\n",
        "        # Q2 architecture\n",
        "        self.l4 = nn.Linear(state_dim + action_dim, 400)\n",
        "        self.l5 = nn.Linear(400, 300)\n",
        "        self.l6 = nn.Linear(300, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x, u):\n",
        "        xu = torch.cat([x, u], 1)\n",
        "\n",
        "        x1 = F.relu(self.l1(xu))\n",
        "        x1 = F.relu(self.l2(x1))\n",
        "        x1 = self.l3(x1)\n",
        "\n",
        "        x2 = F.relu(self.l4(xu))\n",
        "        x2 = F.relu(self.l5(x2))\n",
        "        x2 = self.l6(x2)\n",
        "        return x1, x2\n",
        "\n",
        "\n",
        "    def Q1(self, x, u):\n",
        "        xu = torch.cat([x, u], 1)\n",
        "\n",
        "        x1 = F.relu(self.l1(xu))\n",
        "        x1 = F.relu(self.l2(x1))\n",
        "        x1 = self.l3(x1)\n",
        "        return x1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2KS-IRHnpVn",
        "colab_type": "text"
      },
      "source": [
        "# Memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQwIQ14VnpV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code based on: \n",
        "# https://github.com/openai/baselines/blob/master/baselines/deepq/replay_buffer.py\n",
        "\n",
        "# Expects tuples of (state, next_state, action, reward, done)\n",
        "class ReplayBuffer(object):\n",
        "    \"\"\"Buffer to store tuples of experience replay\"\"\"\n",
        "    \n",
        "    def __init__(self, max_size=1000000):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            max_size (int): total amount of tuples to store\n",
        "        \"\"\"\n",
        "        \n",
        "        self.storage = []\n",
        "        self.max_size = max_size\n",
        "        self.ptr = 0\n",
        "\n",
        "    def add(self, data):\n",
        "        \"\"\"Add experience tuples to buffer\n",
        "        \n",
        "        Args:\n",
        "            data (tuple): experience replay tuple\n",
        "        \"\"\"\n",
        "        \n",
        "        if len(self.storage) == self.max_size:\n",
        "            self.storage[int(self.ptr)] = data\n",
        "            self.ptr = (self.ptr + 1) % self.max_size\n",
        "        else:\n",
        "            self.storage.append(data)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        \"\"\"Samples a random amount of experiences from buffer of batch size\n",
        "        \n",
        "        Args:\n",
        "            batch_size (int): size of sample\n",
        "        \"\"\"\n",
        "        \n",
        "        ind = np.random.randint(0, len(self.storage), size=batch_size)\n",
        "        states, actions, next_states, rewards, dones = [], [], [], [], []\n",
        "\n",
        "        for i in ind: \n",
        "            s, a, s_, r, d = self.storage[i]\n",
        "            states.append(np.array(s, copy=False))\n",
        "            actions.append(np.array(a, copy=False))\n",
        "            next_states.append(np.array(s_, copy=False))\n",
        "            rewards.append(np.array(r, copy=False))\n",
        "            dones.append(np.array(d, copy=False))\n",
        "\n",
        "        return np.array(states), np.array(actions), np.array(next_states), np.array(rewards).reshape(-1, 1), np.array(dones).reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UDI07-nnpV-",
        "colab_type": "text"
      },
      "source": [
        "# Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0l6u_4knpWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TD3(object):\n",
        "    \"\"\"Agent class that handles the training of the networks and provides outputs as actions\n",
        "    \n",
        "        Args:\n",
        "            state_dim (int): state size\n",
        "            action_dim (int): action size\n",
        "            max_action (float): highest action to take\n",
        "            device (device): cuda or cpu to process tensors\n",
        "            env (env): gym environment to use\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, state_dim, action_dim, max_action, env):\n",
        "        self.actor = Actor(state_dim, action_dim, max_action).to(device)\n",
        "        self.actor_target = Actor(state_dim, action_dim, max_action).to(device)\n",
        "        self.actor_target.load_state_dict(self.actor.state_dict())\n",
        "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=1e-3)\n",
        "\n",
        "        self.critic = Critic(state_dim, action_dim).to(device)\n",
        "        self.critic_target = Critic(state_dim, action_dim).to(device)\n",
        "        self.critic_target.load_state_dict(self.critic.state_dict())\n",
        "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=1e-3)\n",
        "\n",
        "        self.max_action = max_action\n",
        "        self.env = env\n",
        "\n",
        "\n",
        "        \n",
        "    def select_action(self, state, noise=0.1):\n",
        "        \"\"\"Select an appropriate action from the agent policy\n",
        "        \n",
        "            Args:\n",
        "                state (array): current state of environment\n",
        "                noise (float): how much noise to add to acitons\n",
        "                \n",
        "            Returns:\n",
        "                action (float): action clipped within action range\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        state = torch.FloatTensor(state.reshape(1, -1)).to(device)\n",
        "        \n",
        "        action = self.actor(state).cpu().data.numpy().flatten()\n",
        "        if noise != 0: \n",
        "            action = (action + np.random.normal(0, noise, size=self.env.action_space.shape[0]))\n",
        "            \n",
        "        return action.clip(self.env.action_space.low, self.env.action_space.high)\n",
        "\n",
        "    \n",
        "    def train(self, replay_buffer, iterations, batch_size=100, discount=0.99, tau=0.005, policy_noise=0.2, noise_clip=0.5, policy_freq=2):\n",
        "        \"\"\"Train and update actor and critic networks\n",
        "        \n",
        "            Args:\n",
        "                replay_buffer (ReplayBuffer): buffer for experience replay\n",
        "                iterations (int): how many times to run training\n",
        "                batch_size(int): batch size to sample from replay buffer\n",
        "                discount (float): discount factor\n",
        "                tau (float): soft update for main networks to target networks\n",
        "                \n",
        "            Return:\n",
        "                actor_loss (float): loss from actor network\n",
        "                critic_loss (float): loss from critic network\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        for it in range(iterations):\n",
        "\n",
        "            # Sample replay buffer \n",
        "            x, y, u, r, d = replay_buffer.sample(batch_size)\n",
        "            state = torch.FloatTensor(x).to(device)\n",
        "            action = torch.FloatTensor(u).to(device)\n",
        "            next_state = torch.FloatTensor(y).to(device)\n",
        "            done = torch.FloatTensor(1 - d).to(device)\n",
        "            reward = torch.FloatTensor(r).to(device)\n",
        "\n",
        "            # Select action according to policy and add clipped noise \n",
        "            noise = torch.FloatTensor(u).data.normal_(0, policy_noise).to(device)\n",
        "            noise = noise.clamp(-noise_clip, noise_clip)\n",
        "            next_action = (self.actor_target(next_state) + noise).clamp(-self.max_action, self.max_action)\n",
        "\n",
        "            # Compute the target Q value\n",
        "            target_Q1, target_Q2 = self.critic_target(next_state, next_action)\n",
        "            target_Q = torch.min(target_Q1, target_Q2)\n",
        "            target_Q = reward + (done * discount * target_Q).detach()\n",
        "\n",
        "            # Get current Q estimates\n",
        "            current_Q1, current_Q2 = self.critic(state, action)\n",
        "\n",
        "            # Compute critic loss\n",
        "            critic_loss = F.mse_loss(current_Q1, target_Q) + F.mse_loss(current_Q2, target_Q) \n",
        "\n",
        "            # Optimize the critic\n",
        "            self.critic_optimizer.zero_grad()\n",
        "            critic_loss.backward()\n",
        "            self.critic_optimizer.step()\n",
        "\n",
        "            # Delayed policy updates\n",
        "            if it % policy_freq == 0:\n",
        "\n",
        "                # Compute actor loss\n",
        "                actor_loss = -self.critic.Q1(state, self.actor(state)).mean()\n",
        "\n",
        "                # Optimize the actor \n",
        "                self.actor_optimizer.zero_grad()\n",
        "                actor_loss.backward()\n",
        "                self.actor_optimizer.step()\n",
        "\n",
        "                # Update the frozen target models\n",
        "                for param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
        "                    target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
        "\n",
        "                for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
        "                    target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
        "\n",
        "\n",
        "    def save(self, filename, directory):\n",
        "        torch.save(self.actor.state_dict(), '%s/%s_actor.pth' % (directory, filename))\n",
        "        torch.save(self.critic.state_dict(), '%s/%s_critic.pth' % (directory, filename))\n",
        "\n",
        "\n",
        "    def load(self, filename=\"best_avg\", directory=\"./saves\"):\n",
        "        self.actor.load_state_dict(torch.load('%s/%s_actor.pth' % (directory, filename)))\n",
        "        self.critic.load_state_dict(torch.load('%s/%s_critic.pth' % (directory, filename)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ1Kf78_npWE",
        "colab_type": "text"
      },
      "source": [
        "# Runner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYzKUCOnnpWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Runner():\n",
        "    \"\"\"Carries out the environment steps and adds experiences to memory\"\"\"\n",
        "    \n",
        "    def __init__(self, env, agent, replay_buffer):\n",
        "        \n",
        "        self.env = env\n",
        "        self.agent = agent\n",
        "        self.replay_buffer = replay_buffer\n",
        "        self.obs = env.reset()\n",
        "        self.done = False\n",
        "        \n",
        "    def next_step(self, episode_timesteps, noise=0.1):\n",
        "        \n",
        "        action = self.agent.select_action(np.array(self.obs), noise=0.1)\n",
        "        \n",
        "        # Perform action\n",
        "        new_obs, reward, done, _ = self.env.step(action) \n",
        "        done_bool = 0 if episode_timesteps + 1 == 200 else float(done)\n",
        "    \n",
        "        # Store data in replay buffer\n",
        "        replay_buffer.add((self.obs, new_obs, action, reward, done_bool))\n",
        "        \n",
        "        self.obs = new_obs\n",
        "        \n",
        "        if done:\n",
        "            self.obs = self.env.reset()\n",
        "            done = False\n",
        "            \n",
        "            return reward, True\n",
        "        \n",
        "        return reward, done"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhmggP7TnpWH",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g6CYzr2npWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_policy(policy, env, eval_episodes=100,render=False):\n",
        "    \"\"\"run several episodes using the best agent policy\n",
        "        \n",
        "        Args:\n",
        "            policy (agent): agent to evaluate\n",
        "            env (env): gym environment\n",
        "            eval_episodes (int): how many test episodes to run\n",
        "            render (bool): show training\n",
        "        \n",
        "        Returns:\n",
        "            avg_reward (float): average reward over the number of evaluations\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    avg_reward = 0.\n",
        "    for i in range(eval_episodes):\n",
        "        obs = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            if render:\n",
        "                env.render()\n",
        "            action = policy.select_action(np.array(obs), noise=0)\n",
        "            obs, reward, done, _ = env.step(action)\n",
        "            avg_reward += reward\n",
        "\n",
        "    avg_reward /= eval_episodes\n",
        "\n",
        "    print(\"\\n---------------------------------------\")\n",
        "    print(\"Evaluation over {:d} episodes: {:f}\" .format(eval_episodes, avg_reward))\n",
        "    print(\"---------------------------------------\")\n",
        "    return avg_reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5uXjG0inpWL",
        "colab_type": "text"
      },
      "source": [
        "# Observation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zw822TgnpWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def observe(env,replay_buffer, observation_steps):\n",
        "    \"\"\"run episodes while taking random actions and filling replay_buffer\n",
        "    \n",
        "        Args:\n",
        "            env (env): gym environment\n",
        "            replay_buffer(ReplayBuffer): buffer to store experience replay\n",
        "            observation_steps (int): how many steps to observe for\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    time_steps = 0\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while time_steps < observation_steps:\n",
        "        action = env.action_space.sample()\n",
        "        new_obs, reward, done, _ = env.step(action)\n",
        "\n",
        "        replay_buffer.add((obs, new_obs, action, reward, done))\n",
        "\n",
        "        obs = new_obs\n",
        "        time_steps += 1\n",
        "\n",
        "        if done:\n",
        "            obs = env.reset()\n",
        "            done = False\n",
        "\n",
        "        print(\"\\rPopulating Buffer {}/{}.\".format(time_steps, observation_steps), end=\"\")\n",
        "        sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZWuqwO1npWP",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6877aX9BnpWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(agent, test_env):\n",
        "    \"\"\"Train the agent for exploration steps\n",
        "    \n",
        "        Args:\n",
        "            agent (Agent): agent to use\n",
        "            env (environment): gym environment\n",
        "            writer (SummaryWriter): tensorboard writer\n",
        "            exploration (int): how many training steps to run\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    total_timesteps = 0\n",
        "    timesteps_since_eval = 0\n",
        "    episode_num = 0\n",
        "    episode_reward = 0\n",
        "    episode_timesteps = 0\n",
        "    done = False \n",
        "    obs = env.reset()\n",
        "    evaluations = []\n",
        "    rewards = []\n",
        "    best_avg = -2000\n",
        "    \n",
        "    writer = SummaryWriter(comment=\"-TD3_Baseline_HalfCheetah\")\n",
        "    \n",
        "    while total_timesteps < EXPLORATION:\n",
        "    \n",
        "        if done: \n",
        "\n",
        "            if total_timesteps != 0: \n",
        "                rewards.append(episode_reward)\n",
        "                avg_reward = np.mean(rewards[-100:])\n",
        "                \n",
        "                writer.add_scalar(\"avg_reward\", avg_reward, total_timesteps)\n",
        "                writer.add_scalar(\"reward_step\", reward, total_timesteps)\n",
        "                writer.add_scalar(\"episode_reward\", episode_reward, total_timesteps)\n",
        "                \n",
        "                if best_avg < avg_reward:\n",
        "                    best_avg = avg_reward\n",
        "                    print(\"saving best model....\\n\")\n",
        "                    agent.save(\"best_avg\",\"saves\")\n",
        "\n",
        "                print(\"\\rTotal T: {:d} Episode Num: {:d} Reward: {:f} Avg Reward: {:f}\".format(\n",
        "                    total_timesteps, episode_num, episode_reward, avg_reward), end=\"\")\n",
        "                sys.stdout.flush()\n",
        "\n",
        "\n",
        "                if avg_reward >= REWARD_THRESH:\n",
        "                    break\n",
        "\n",
        "                agent.train(replay_buffer, episode_timesteps, BATCH_SIZE, GAMMA, TAU, NOISE, NOISE_CLIP, POLICY_FREQUENCY)\n",
        "\n",
        "                # Evaluate episode\n",
        "                if timesteps_since_eval >= EVAL_FREQUENCY:\n",
        "                    timesteps_since_eval %= EVAL_FREQUENCY\n",
        "                    eval_reward = evaluate_policy(agent, test_env)\n",
        "                    evaluations.append(avg_reward)\n",
        "                    writer.add_scalar(\"eval_reward\", eval_reward, total_timesteps)\n",
        "\n",
        "                    if best_avg < eval_reward:\n",
        "                        best_avg = eval_reward\n",
        "                        print(\"saving best model....\\n\")\n",
        "                        agent.save(\"best_avg\",\"saves\")\n",
        "\n",
        "                episode_reward = 0\n",
        "                episode_timesteps = 0\n",
        "                episode_num += 1 \n",
        "\n",
        "        reward, done = runner.next_step(episode_timesteps)\n",
        "        episode_reward += reward\n",
        "\n",
        "        episode_timesteps += 1\n",
        "        total_timesteps += 1\n",
        "        timesteps_since_eval += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfwWrVMOnpWT",
        "colab_type": "text"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyOO_23tnpWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ENV = \"Pendulum-v0\"#\"Pendulum-v0\" #HalfCheetahMuJoCoEnv-v0\t\n",
        "SEED = 0\n",
        "OBSERVATION = 10000\n",
        "EXPLORATION = 5000000\n",
        "BATCH_SIZE = 100\n",
        "GAMMA = 0.99\n",
        "TAU = 0.005\n",
        "NOISE = 0.2\n",
        "NOISE_CLIP = 0.5\n",
        "EXPLORE_NOISE = 0.1\n",
        "POLICY_FREQUENCY = 2\n",
        "EVAL_FREQUENCY = 5000\n",
        "REWARD_THRESH = 8000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE5NjQdcnpWV",
        "colab_type": "text"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgao3UPhnpWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make(ENV)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set seeds\n",
        "env.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.shape[0] \n",
        "max_action = float(env.action_space.high[0])\n",
        "\n",
        "policy = TD3(state_dim, action_dim, max_action, env)\n",
        "\n",
        "replay_buffer = ReplayBuffer()\n",
        "\n",
        "runner = Runner(env, policy, replay_buffer)\n",
        "\n",
        "total_timesteps = 0\n",
        "timesteps_since_eval = 0\n",
        "episode_num = 0\n",
        "done = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alYTdprknpWY",
        "colab_type": "code",
        "outputId": "4c1f9a20-235c-4dc3-e2ea-3e2e820f7fb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Populate replay buffer\n",
        "observe(env, replay_buffer, OBSERVATION)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating Buffer 10000/10000."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DzONcNZnpWd",
        "colab_type": "code",
        "outputId": "612e7739-7810-4193-f88c-657c2208db5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train agent\n",
        "train(policy, env)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saving best model....\n",
            "\n",
            "Total T: 4800 Episode Num: 23 Reward: -603.096721 Avg Reward: -1259.871510saving best model....\n",
            "\n",
            "Total T: 5000 Episode Num: 24 Reward: -722.750267 Avg Reward: -1238.386660\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -387.920471\n",
            "---------------------------------------\n",
            "saving best model....\n",
            "\n",
            "Total T: 10001 Episode Num: 50 Reward: -131.721027 Avg Reward: -698.314601\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.798520\n",
            "---------------------------------------\n",
            "saving best model....\n",
            "\n",
            "Total T: 15002 Episode Num: 76 Reward: -122.555019 Avg Reward: -505.503081\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -168.877200\n",
            "---------------------------------------\n",
            "Total T: 20003 Episode Num: 102 Reward: -235.918097 Avg Reward: -398.207284\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -151.847979\n",
            "---------------------------------------\n",
            "Total T: 25004 Episode Num: 128 Reward: -344.852213 Avg Reward: -160.288249\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -135.193575\n",
            "---------------------------------------\n",
            "saving best model....\n",
            "\n",
            "Total T: 30005 Episode Num: 154 Reward: -236.353658 Avg Reward: -164.682376\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.706353\n",
            "---------------------------------------\n",
            "Total T: 35006 Episode Num: 180 Reward: -117.075385 Avg Reward: -171.640776\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -149.752955\n",
            "---------------------------------------\n",
            "Total T: 40007 Episode Num: 206 Reward: -5.992129 Avg Reward: -149.138574\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.486963\n",
            "---------------------------------------\n",
            "Total T: 45008 Episode Num: 232 Reward: -5.075935 Avg Reward: -146.157379\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.462769\n",
            "---------------------------------------\n",
            "Total T: 48609 Episode Num: 251 Reward: -127.745479 Avg Reward: -135.610976saving best model....\n",
            "\n",
            "Total T: 48809 Episode Num: 252 Reward: -238.106626 Avg Reward: -134.679996saving best model....\n",
            "\n",
            "Total T: 49009 Episode Num: 253 Reward: -3.881976 Avg Reward: -132.295350saving best model....\n",
            "\n",
            "Total T: 50009 Episode Num: 258 Reward: -127.329855 Avg Reward: -131.159465\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.530695\n",
            "---------------------------------------\n",
            "saving best model....\n",
            "\n",
            "Total T: 50210 Episode Num: 260 Reward: -236.120966 Avg Reward: -129.917130saving best model....\n",
            "\n",
            "Total T: 50410 Episode Num: 261 Reward: -6.076339 Avg Reward: -128.778663saving best model....\n",
            "\n",
            "Total T: 50610 Episode Num: 262 Reward: -130.855321 Avg Reward: -127.654247saving best model....\n",
            "\n",
            "Total T: 51210 Episode Num: 265 Reward: -125.434175 Avg Reward: -128.767813saving best model....\n",
            "\n",
            "Total T: 53410 Episode Num: 276 Reward: -2.276500 Avg Reward: -128.053726saving best model....\n",
            "\n",
            "Total T: 53610 Episode Num: 277 Reward: -3.920771 Avg Reward: -126.823367saving best model....\n",
            "\n",
            "Total T: 53810 Episode Num: 278 Reward: -336.720104 Avg Reward: -126.603715saving best model....\n",
            "\n",
            "Total T: 55010 Episode Num: 284 Reward: -125.105746 Avg Reward: -132.576109\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -150.781722\n",
            "---------------------------------------\n",
            "Total T: 60011 Episode Num: 310 Reward: -235.339863 Avg Reward: -143.626958\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.517579\n",
            "---------------------------------------\n",
            "Total T: 65012 Episode Num: 336 Reward: -5.744457 Avg Reward: -150.754032\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -138.469024\n",
            "---------------------------------------\n",
            "Total T: 70013 Episode Num: 362 Reward: -232.966440 Avg Reward: -158.514407\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -149.945538\n",
            "---------------------------------------\n",
            "Total T: 75014 Episode Num: 388 Reward: -229.315751 Avg Reward: -156.356715\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -137.692870\n",
            "---------------------------------------\n",
            "Total T: 80015 Episode Num: 414 Reward: -119.444470 Avg Reward: -143.482099\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -144.947268\n",
            "---------------------------------------\n",
            "Total T: 85016 Episode Num: 440 Reward: -337.880809 Avg Reward: -142.975612\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -157.088687\n",
            "---------------------------------------\n",
            "Total T: 90017 Episode Num: 466 Reward: -323.300030 Avg Reward: -142.459951\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.270341\n",
            "---------------------------------------\n",
            "Total T: 95018 Episode Num: 492 Reward: -124.044936 Avg Reward: -140.017620\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -169.432375\n",
            "---------------------------------------\n",
            "Total T: 100019 Episode Num: 518 Reward: -223.578334 Avg Reward: -150.163502\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.569063\n",
            "---------------------------------------\n",
            "Total T: 105020 Episode Num: 544 Reward: -119.577739 Avg Reward: -152.176151\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -151.997675\n",
            "---------------------------------------\n",
            "Total T: 110021 Episode Num: 570 Reward: -124.805823 Avg Reward: -145.535917\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -136.697875\n",
            "---------------------------------------\n",
            "Total T: 115022 Episode Num: 596 Reward: -1.192696 Avg Reward: -143.355020\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -132.841568\n",
            "---------------------------------------\n",
            "Total T: 120023 Episode Num: 622 Reward: -231.953441 Avg Reward: -136.896938\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -151.439755\n",
            "---------------------------------------\n",
            "Total T: 123224 Episode Num: 639 Reward: -114.887502 Avg Reward: -126.847898saving best model....\n",
            "\n",
            "Total T: 123624 Episode Num: 641 Reward: -119.735718 Avg Reward: -125.725122saving best model....\n",
            "\n",
            "Total T: 125024 Episode Num: 648 Reward: -119.007238 Avg Reward: -128.475631\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -151.478667\n",
            "---------------------------------------\n",
            "Total T: 130025 Episode Num: 674 Reward: -115.216604 Avg Reward: -133.645939\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -149.141633\n",
            "---------------------------------------\n",
            "Total T: 135026 Episode Num: 700 Reward: -123.758406 Avg Reward: -132.691372\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -149.113074\n",
            "---------------------------------------\n",
            "Total T: 140027 Episode Num: 726 Reward: -125.405445 Avg Reward: -143.259755\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -136.298880\n",
            "---------------------------------------\n",
            "Total T: 145028 Episode Num: 752 Reward: -250.146860 Avg Reward: -152.858862\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -144.835185\n",
            "---------------------------------------\n",
            "Total T: 150029 Episode Num: 778 Reward: -127.709559 Avg Reward: -156.237790\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -154.768546\n",
            "---------------------------------------\n",
            "Total T: 155030 Episode Num: 804 Reward: -233.020598 Avg Reward: -149.831184\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -156.886488\n",
            "---------------------------------------\n",
            "Total T: 160031 Episode Num: 830 Reward: -116.007556 Avg Reward: -148.258933\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -152.030262\n",
            "---------------------------------------\n",
            "Total T: 165032 Episode Num: 856 Reward: -244.837696 Avg Reward: -143.321241\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.576442\n",
            "---------------------------------------\n",
            "Total T: 170033 Episode Num: 882 Reward: -353.122497 Avg Reward: -142.617431\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -150.948215\n",
            "---------------------------------------\n",
            "Total T: 175034 Episode Num: 908 Reward: -117.251271 Avg Reward: -141.022446\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -137.964292\n",
            "---------------------------------------\n",
            "Total T: 180035 Episode Num: 934 Reward: -125.182530 Avg Reward: -139.254756\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.482613\n",
            "---------------------------------------\n",
            "Total T: 185036 Episode Num: 960 Reward: -119.802244 Avg Reward: -134.859163\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.271954\n",
            "---------------------------------------\n",
            "Total T: 190037 Episode Num: 986 Reward: -115.013121 Avg Reward: -130.109018\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -145.811724\n",
            "---------------------------------------\n",
            "Total T: 195038 Episode Num: 1012 Reward: -118.445893 Avg Reward: -129.426216\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.517200\n",
            "---------------------------------------\n",
            "Total T: 200039 Episode Num: 1038 Reward: -224.806845 Avg Reward: -138.433039\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -139.943453\n",
            "---------------------------------------\n",
            "Total T: 205040 Episode Num: 1064 Reward: -307.324174 Avg Reward: -145.643810\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -144.328625\n",
            "---------------------------------------\n",
            "Total T: 210041 Episode Num: 1090 Reward: -243.205575 Avg Reward: -148.523811\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -132.994678\n",
            "---------------------------------------\n",
            "Total T: 215042 Episode Num: 1116 Reward: -126.190385 Avg Reward: -146.693333\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.720822\n",
            "---------------------------------------\n",
            "Total T: 220043 Episode Num: 1142 Reward: -119.622887 Avg Reward: -139.441252\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -151.124271\n",
            "---------------------------------------\n",
            "Total T: 225044 Episode Num: 1168 Reward: -231.630679 Avg Reward: -139.593452\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.835852\n",
            "---------------------------------------\n",
            "Total T: 230045 Episode Num: 1194 Reward: -234.607893 Avg Reward: -147.373665\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.323119\n",
            "---------------------------------------\n",
            "Total T: 235046 Episode Num: 1220 Reward: -116.640833 Avg Reward: -154.344614\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -133.649232\n",
            "---------------------------------------\n",
            "Total T: 240047 Episode Num: 1246 Reward: -122.403765 Avg Reward: -159.753970\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -147.636497\n",
            "---------------------------------------\n",
            "Total T: 245048 Episode Num: 1272 Reward: -125.662294 Avg Reward: -155.641135\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -144.904314\n",
            "---------------------------------------\n",
            "Total T: 250049 Episode Num: 1298 Reward: -121.751124 Avg Reward: -149.299052\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.929036\n",
            "---------------------------------------\n",
            "Total T: 255050 Episode Num: 1324 Reward: -223.802304 Avg Reward: -144.222016\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -133.855144\n",
            "---------------------------------------\n",
            "Total T: 260051 Episode Num: 1350 Reward: -1.667735 Avg Reward: -135.312656\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -144.474727\n",
            "---------------------------------------\n",
            "Total T: 265052 Episode Num: 1376 Reward: -223.188891 Avg Reward: -130.876768\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.901605\n",
            "---------------------------------------\n",
            "Total T: 270053 Episode Num: 1402 Reward: -1.951272 Avg Reward: -130.299024\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -143.034361\n",
            "---------------------------------------\n",
            "Total T: 271254 Episode Num: 1409 Reward: -121.365418 Avg Reward: -125.896203saving best model....\n",
            "\n",
            "Total T: 271454 Episode Num: 1410 Reward: -1.825065 Avg Reward: -124.679447saving best model....\n",
            "\n",
            "Total T: 271654 Episode Num: 1411 Reward: -117.506809 Avg Reward: -124.594415saving best model....\n",
            "\n",
            "Total T: 273654 Episode Num: 1421 Reward: -229.632021 Avg Reward: -125.075759saving best model....\n",
            "\n",
            "Total T: 275054 Episode Num: 1428 Reward: -124.739911 Avg Reward: -128.723424\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -153.461923\n",
            "---------------------------------------\n",
            "Total T: 280055 Episode Num: 1454 Reward: -117.669786 Avg Reward: -134.018677\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -147.203200\n",
            "---------------------------------------\n",
            "Total T: 285056 Episode Num: 1480 Reward: -280.009114 Avg Reward: -137.919228\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -140.154589\n",
            "---------------------------------------\n",
            "Total T: 290057 Episode Num: 1506 Reward: -124.076258 Avg Reward: -141.397901\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -140.985448\n",
            "---------------------------------------\n",
            "Total T: 295058 Episode Num: 1532 Reward: -123.033407 Avg Reward: -140.650200\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.972937\n",
            "---------------------------------------\n",
            "Total T: 300059 Episode Num: 1558 Reward: -115.808927 Avg Reward: -137.864783\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.544961\n",
            "---------------------------------------\n",
            "Total T: 305060 Episode Num: 1584 Reward: -122.425315 Avg Reward: -136.843975\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.368952\n",
            "---------------------------------------\n",
            "Total T: 310061 Episode Num: 1610 Reward: -120.898105 Avg Reward: -140.787549\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.264861\n",
            "---------------------------------------\n",
            "Total T: 315062 Episode Num: 1636 Reward: -125.534493 Avg Reward: -141.076193\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -134.257349\n",
            "---------------------------------------\n",
            "Total T: 320063 Episode Num: 1662 Reward: -114.279252 Avg Reward: -147.363485\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -133.098053\n",
            "---------------------------------------\n",
            "Total T: 325064 Episode Num: 1688 Reward: -124.549299 Avg Reward: -148.528338\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -138.404043\n",
            "---------------------------------------\n",
            "Total T: 330065 Episode Num: 1714 Reward: -118.862285 Avg Reward: -142.743474\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.839574\n",
            "---------------------------------------\n",
            "Total T: 335066 Episode Num: 1740 Reward: -129.135239 Avg Reward: -151.484712\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -158.840708\n",
            "---------------------------------------\n",
            "Total T: 340067 Episode Num: 1766 Reward: -0.777679 Avg Reward: -150.943629\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -155.902200\n",
            "---------------------------------------\n",
            "Total T: 345068 Episode Num: 1792 Reward: -128.171168 Avg Reward: -150.601466\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -155.374336\n",
            "---------------------------------------\n",
            "Total T: 350069 Episode Num: 1818 Reward: -122.461219 Avg Reward: -145.129279\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -135.295293\n",
            "---------------------------------------\n",
            "Total T: 355070 Episode Num: 1844 Reward: -115.024468 Avg Reward: -140.829685\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.656809\n",
            "---------------------------------------\n",
            "Total T: 360071 Episode Num: 1870 Reward: -129.110473 Avg Reward: -143.957106\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.798216\n",
            "---------------------------------------\n",
            "Total T: 365072 Episode Num: 1896 Reward: -113.606577 Avg Reward: -156.316337\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -144.410879\n",
            "---------------------------------------\n",
            "Total T: 370073 Episode Num: 1922 Reward: -117.735238 Avg Reward: -159.707628\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.078952\n",
            "---------------------------------------\n",
            "Total T: 375074 Episode Num: 1948 Reward: -114.898523 Avg Reward: -156.124062\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -130.820629\n",
            "---------------------------------------\n",
            "Total T: 380075 Episode Num: 1974 Reward: -115.586481 Avg Reward: -146.068599\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -132.008958\n",
            "---------------------------------------\n",
            "Total T: 385076 Episode Num: 2000 Reward: -128.076134 Avg Reward: -135.080016\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -137.196615\n",
            "---------------------------------------\n",
            "Total T: 390077 Episode Num: 2026 Reward: -121.769080 Avg Reward: -138.169571\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -143.408196\n",
            "---------------------------------------\n",
            "Total T: 395078 Episode Num: 2052 Reward: -124.228905 Avg Reward: -137.410341\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -144.129769\n",
            "---------------------------------------\n",
            "Total T: 400079 Episode Num: 2078 Reward: -131.999167 Avg Reward: -130.246776\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -143.726878\n",
            "---------------------------------------\n",
            "Total T: 405080 Episode Num: 2104 Reward: -126.790201 Avg Reward: -137.121146\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -140.130132\n",
            "---------------------------------------\n",
            "Total T: 410081 Episode Num: 2130 Reward: -119.960410 Avg Reward: -130.475035\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -158.631896\n",
            "---------------------------------------\n",
            "Total T: 415082 Episode Num: 2156 Reward: -308.325868 Avg Reward: -137.676154\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -143.590535\n",
            "---------------------------------------\n",
            "Total T: 420083 Episode Num: 2182 Reward: -122.583207 Avg Reward: -141.538790\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -134.147236\n",
            "---------------------------------------\n",
            "Total T: 425084 Episode Num: 2208 Reward: -124.846911 Avg Reward: -142.344370\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -150.633543\n",
            "---------------------------------------\n",
            "Total T: 430085 Episode Num: 2234 Reward: -127.332197 Avg Reward: -149.853123\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -144.459225\n",
            "---------------------------------------\n",
            "Total T: 435086 Episode Num: 2260 Reward: -123.192758 Avg Reward: -149.640447\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -143.432304\n",
            "---------------------------------------\n",
            "Total T: 440087 Episode Num: 2286 Reward: -120.086227 Avg Reward: -149.589741\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -151.945997\n",
            "---------------------------------------\n",
            "Total T: 445088 Episode Num: 2312 Reward: -246.348837 Avg Reward: -142.757755\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -128.555240\n",
            "---------------------------------------\n",
            "Total T: 450089 Episode Num: 2338 Reward: -124.964633 Avg Reward: -141.918950\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.931503\n",
            "---------------------------------------\n",
            "Total T: 455090 Episode Num: 2364 Reward: -125.900877 Avg Reward: -143.714676\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -140.585821\n",
            "---------------------------------------\n",
            "Total T: 460091 Episode Num: 2390 Reward: -129.567639 Avg Reward: -138.815683\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -151.797765\n",
            "---------------------------------------\n",
            "Total T: 465092 Episode Num: 2416 Reward: -116.888191 Avg Reward: -136.882432\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -131.833796\n",
            "---------------------------------------\n",
            "Total T: 470093 Episode Num: 2442 Reward: -123.828670 Avg Reward: -133.487363\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.398100\n",
            "---------------------------------------\n",
            "Total T: 475094 Episode Num: 2468 Reward: -234.718012 Avg Reward: -135.420118\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -151.145417\n",
            "---------------------------------------\n",
            "Total T: 480095 Episode Num: 2494 Reward: -123.679977 Avg Reward: -143.433529\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -119.734766\n",
            "---------------------------------------\n",
            "saving best model....\n",
            "\n",
            "Total T: 485096 Episode Num: 2520 Reward: -117.693266 Avg Reward: -144.661487\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -134.963103\n",
            "---------------------------------------\n",
            "Total T: 490097 Episode Num: 2546 Reward: -245.678327 Avg Reward: -157.834128\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -143.661861\n",
            "---------------------------------------\n",
            "Total T: 495098 Episode Num: 2572 Reward: -1.360227 Avg Reward: -158.220605\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -143.455966\n",
            "---------------------------------------\n",
            "Total T: 500099 Episode Num: 2598 Reward: -243.155762 Avg Reward: -153.103326\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -129.453010\n",
            "---------------------------------------\n",
            "Total T: 505100 Episode Num: 2624 Reward: -297.759534 Avg Reward: -153.873464\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -153.302473\n",
            "---------------------------------------\n",
            "Total T: 510101 Episode Num: 2650 Reward: -131.521448 Avg Reward: -146.969147\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -152.916022\n",
            "---------------------------------------\n",
            "Total T: 515102 Episode Num: 2676 Reward: -117.243756 Avg Reward: -144.429592\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -150.157366\n",
            "---------------------------------------\n",
            "Total T: 520103 Episode Num: 2702 Reward: -231.853279 Avg Reward: -138.233310\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -154.567423\n",
            "---------------------------------------\n",
            "Total T: 525104 Episode Num: 2728 Reward: -117.689522 Avg Reward: -132.136766\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -119.719215\n",
            "---------------------------------------\n",
            "saving best model....\n",
            "\n",
            "Total T: 530105 Episode Num: 2754 Reward: -299.577574 Avg Reward: -133.526023\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -140.351869\n",
            "---------------------------------------\n",
            "Total T: 535106 Episode Num: 2780 Reward: -127.261259 Avg Reward: -136.878504\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.548983\n",
            "---------------------------------------\n",
            "Total T: 540107 Episode Num: 2806 Reward: -258.774717 Avg Reward: -140.149025\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -144.566875\n",
            "---------------------------------------\n",
            "Total T: 545108 Episode Num: 2832 Reward: -120.449511 Avg Reward: -144.413965\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -140.535084\n",
            "---------------------------------------\n",
            "Total T: 550109 Episode Num: 2858 Reward: -224.515491 Avg Reward: -143.228104\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -149.011470\n",
            "---------------------------------------\n",
            "Total T: 555110 Episode Num: 2884 Reward: -1.359512 Avg Reward: -139.475467\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.020152\n",
            "---------------------------------------\n",
            "Total T: 560111 Episode Num: 2910 Reward: -237.123643 Avg Reward: -147.396429\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.781125\n",
            "---------------------------------------\n",
            "Total T: 565112 Episode Num: 2936 Reward: -242.438599 Avg Reward: -149.971620\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -154.799377\n",
            "---------------------------------------\n",
            "Total T: 570113 Episode Num: 2962 Reward: -120.210778 Avg Reward: -150.757960\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -131.735625\n",
            "---------------------------------------\n",
            "Total T: 575114 Episode Num: 2988 Reward: -4.229691 Avg Reward: -149.140124\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -161.022911\n",
            "---------------------------------------\n",
            "Total T: 580115 Episode Num: 3014 Reward: -226.948745 Avg Reward: -144.798712\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -144.948054\n",
            "---------------------------------------\n",
            "Total T: 585116 Episode Num: 3040 Reward: -120.554021 Avg Reward: -136.893223\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -141.834005\n",
            "---------------------------------------\n",
            "Total T: 590117 Episode Num: 3066 Reward: -221.598827 Avg Reward: -139.391132\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -153.016350\n",
            "---------------------------------------\n",
            "Total T: 595118 Episode Num: 3092 Reward: -125.336559 Avg Reward: -147.265765\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -149.506073\n",
            "---------------------------------------\n",
            "Total T: 600119 Episode Num: 3118 Reward: -126.106961 Avg Reward: -146.350242\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -151.654914\n",
            "---------------------------------------\n",
            "Total T: 605120 Episode Num: 3144 Reward: -234.821282 Avg Reward: -142.703088\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -147.022656\n",
            "---------------------------------------\n",
            "Total T: 610121 Episode Num: 3170 Reward: -0.583983 Avg Reward: -137.892869\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -138.988726\n",
            "---------------------------------------\n",
            "Total T: 615122 Episode Num: 3196 Reward: -122.176366 Avg Reward: -128.601079\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.384041\n",
            "---------------------------------------\n",
            "Total T: 620123 Episode Num: 3222 Reward: -0.506989 Avg Reward: -122.196971\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -140.317100\n",
            "---------------------------------------\n",
            "Total T: 625124 Episode Num: 3248 Reward: -126.930462 Avg Reward: -130.107257\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -150.572164\n",
            "---------------------------------------\n",
            "Total T: 630125 Episode Num: 3274 Reward: -116.715176 Avg Reward: -134.590791\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -127.705617\n",
            "---------------------------------------\n",
            "Total T: 635126 Episode Num: 3300 Reward: -131.825433 Avg Reward: -140.985506\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -135.581015\n",
            "---------------------------------------\n",
            "Total T: 640127 Episode Num: 3326 Reward: -120.814531 Avg Reward: -147.071811\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -134.695519\n",
            "---------------------------------------\n",
            "Total T: 645128 Episode Num: 3352 Reward: -122.260686 Avg Reward: -147.924768\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -145.831929\n",
            "---------------------------------------\n",
            "Total T: 650129 Episode Num: 3378 Reward: -127.985498 Avg Reward: -138.300934\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.954243\n",
            "---------------------------------------\n",
            "Total T: 655130 Episode Num: 3404 Reward: -130.780097 Avg Reward: -135.752944\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -130.790360\n",
            "---------------------------------------\n",
            "Total T: 660131 Episode Num: 3430 Reward: -231.667566 Avg Reward: -136.812850\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -137.450699\n",
            "---------------------------------------\n",
            "Total T: 665132 Episode Num: 3456 Reward: -120.583827 Avg Reward: -137.588174\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -137.451327\n",
            "---------------------------------------\n",
            "Total T: 670133 Episode Num: 3482 Reward: -121.368330 Avg Reward: -138.208478\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -159.942274\n",
            "---------------------------------------\n",
            "Total T: 675134 Episode Num: 3508 Reward: -118.340263 Avg Reward: -137.451700\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -136.723426\n",
            "---------------------------------------\n",
            "Total T: 680135 Episode Num: 3534 Reward: -117.103114 Avg Reward: -136.182716\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -133.463890\n",
            "---------------------------------------\n",
            "Total T: 685136 Episode Num: 3560 Reward: -266.640497 Avg Reward: -136.073236\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -141.707150\n",
            "---------------------------------------\n",
            "Total T: 690137 Episode Num: 3586 Reward: -2.587535 Avg Reward: -135.642127\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.567079\n",
            "---------------------------------------\n",
            "Total T: 695138 Episode Num: 3612 Reward: -215.018220 Avg Reward: -133.409454\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.443018\n",
            "---------------------------------------\n",
            "Total T: 700139 Episode Num: 3638 Reward: -1.741515 Avg Reward: -140.959628\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.851112\n",
            "---------------------------------------\n",
            "Total T: 705140 Episode Num: 3664 Reward: -247.642042 Avg Reward: -138.211304\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -156.994770\n",
            "---------------------------------------\n",
            "Total T: 710141 Episode Num: 3690 Reward: -226.160814 Avg Reward: -143.065031\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -154.664738\n",
            "---------------------------------------\n",
            "Total T: 715142 Episode Num: 3716 Reward: -253.516944 Avg Reward: -147.158539\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -137.064500\n",
            "---------------------------------------\n",
            "Total T: 720143 Episode Num: 3742 Reward: -124.357076 Avg Reward: -137.402631\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -141.337433\n",
            "---------------------------------------\n",
            "Total T: 725144 Episode Num: 3768 Reward: -236.302109 Avg Reward: -138.008423\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -141.758195\n",
            "---------------------------------------\n",
            "Total T: 730145 Episode Num: 3794 Reward: -1.705278 Avg Reward: -145.416049\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -130.485219\n",
            "---------------------------------------\n",
            "Total T: 735146 Episode Num: 3820 Reward: -121.787108 Avg Reward: -144.613415\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -141.011812\n",
            "---------------------------------------\n",
            "Total T: 740147 Episode Num: 3846 Reward: -121.603911 Avg Reward: -149.487111\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -138.030131\n",
            "---------------------------------------\n",
            "Total T: 745148 Episode Num: 3872 Reward: -0.727388 Avg Reward: -141.756732\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -147.740404\n",
            "---------------------------------------\n",
            "Total T: 750149 Episode Num: 3898 Reward: -227.083701 Avg Reward: -135.214338\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -143.927792\n",
            "---------------------------------------\n",
            "Total T: 755150 Episode Num: 3924 Reward: -243.118062 Avg Reward: -137.987211\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -136.417469\n",
            "---------------------------------------\n",
            "Total T: 760151 Episode Num: 3950 Reward: -2.353241 Avg Reward: -136.013777\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -143.600086\n",
            "---------------------------------------\n",
            "Total T: 765152 Episode Num: 3976 Reward: -8.211028 Avg Reward: -136.553330\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -138.736969\n",
            "---------------------------------------\n",
            "Total T: 770153 Episode Num: 4002 Reward: -116.168975 Avg Reward: -131.905270\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -135.792883\n",
            "---------------------------------------\n",
            "Total T: 775154 Episode Num: 4028 Reward: -133.513419 Avg Reward: -141.909892\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -151.896942\n",
            "---------------------------------------\n",
            "Total T: 780155 Episode Num: 4054 Reward: -127.728696 Avg Reward: -140.090708\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.760014\n",
            "---------------------------------------\n",
            "Total T: 785156 Episode Num: 4080 Reward: -246.544326 Avg Reward: -143.040507\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -151.741457\n",
            "---------------------------------------\n",
            "Total T: 790157 Episode Num: 4106 Reward: -132.763749 Avg Reward: -155.846864\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.544973\n",
            "---------------------------------------\n",
            "Total T: 795158 Episode Num: 4132 Reward: -7.056553 Avg Reward: -137.413391\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.700181\n",
            "---------------------------------------\n",
            "Total T: 800159 Episode Num: 4158 Reward: -123.495263 Avg Reward: -145.702523\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -137.115191\n",
            "---------------------------------------\n",
            "Total T: 805160 Episode Num: 4184 Reward: -229.253924 Avg Reward: -141.408891\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -145.965773\n",
            "---------------------------------------\n",
            "Total T: 810161 Episode Num: 4210 Reward: -122.288583 Avg Reward: -124.856103\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -140.152432\n",
            "---------------------------------------\n",
            "Total T: 815162 Episode Num: 4236 Reward: -117.957806 Avg Reward: -129.115129\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.487482\n",
            "---------------------------------------\n",
            "Total T: 818963 Episode Num: 4256 Reward: -120.064003 Avg Reward: -119.836271saving best model....\n",
            "\n",
            "Total T: 819163 Episode Num: 4257 Reward: -2.738928 Avg Reward: -118.665625saving best model....\n",
            "\n",
            "Total T: 820163 Episode Num: 4262 Reward: -114.935020 Avg Reward: -120.986460\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.828211\n",
            "---------------------------------------\n",
            "Total T: 820164 Episode Num: 4263 Reward: -0.003555 Avg Reward: -118.639586saving best model....\n",
            "\n",
            "Total T: 820364 Episode Num: 4264 Reward: -118.453637 Avg Reward: -118.589568saving best model....\n",
            "\n",
            "Total T: 820564 Episode Num: 4265 Reward: -1.581891 Avg Reward: -116.310270saving best model....\n",
            "\n",
            "Total T: 820764 Episode Num: 4266 Reward: -117.613503 Avg Reward: -116.234372saving best model....\n",
            "\n",
            "Total T: 820964 Episode Num: 4267 Reward: -232.323342 Avg Reward: -116.201013saving best model....\n",
            "\n",
            "Total T: 821564 Episode Num: 4270 Reward: -119.598486 Avg Reward: -115.154101saving best model....\n",
            "\n",
            "Total T: 821764 Episode Num: 4271 Reward: -116.931549 Avg Reward: -115.048580saving best model....\n",
            "\n",
            "Total T: 824164 Episode Num: 4283 Reward: -115.364326 Avg Reward: -117.247176saving best model....\n",
            "\n",
            "Total T: 825164 Episode Num: 4288 Reward: -118.553090 Avg Reward: -119.601442\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -137.881616\n",
            "---------------------------------------\n",
            "Total T: 830165 Episode Num: 4314 Reward: -131.253273 Avg Reward: -129.919240\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.050401\n",
            "---------------------------------------\n",
            "Total T: 835166 Episode Num: 4340 Reward: -121.335040 Avg Reward: -138.324514\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.588224\n",
            "---------------------------------------\n",
            "Total T: 840167 Episode Num: 4366 Reward: -240.106536 Avg Reward: -148.561125\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -151.099207\n",
            "---------------------------------------\n",
            "Total T: 845168 Episode Num: 4392 Reward: -119.081705 Avg Reward: -141.029944\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -140.721143\n",
            "---------------------------------------\n",
            "Total T: 850169 Episode Num: 4418 Reward: -229.648564 Avg Reward: -141.534058\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -136.599737\n",
            "---------------------------------------\n",
            "Total T: 855170 Episode Num: 4444 Reward: -125.121074 Avg Reward: -135.300500\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -130.100205\n",
            "---------------------------------------\n",
            "Total T: 860171 Episode Num: 4470 Reward: -114.524677 Avg Reward: -137.768224\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -143.322067\n",
            "---------------------------------------\n",
            "Total T: 865172 Episode Num: 4496 Reward: -125.015186 Avg Reward: -149.231360\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -136.575234\n",
            "---------------------------------------\n",
            "Total T: 870173 Episode Num: 4522 Reward: -222.072342 Avg Reward: -137.924374\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.626692\n",
            "---------------------------------------\n",
            "Total T: 875174 Episode Num: 4548 Reward: -117.156982 Avg Reward: -141.463162\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.851596\n",
            "---------------------------------------\n",
            "Total T: 880175 Episode Num: 4574 Reward: -125.667816 Avg Reward: -140.108061\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -136.793851\n",
            "---------------------------------------\n",
            "Total T: 885176 Episode Num: 4600 Reward: -118.322867 Avg Reward: -138.530417\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -137.638834\n",
            "---------------------------------------\n",
            "Total T: 890177 Episode Num: 4626 Reward: -118.038994 Avg Reward: -149.568908\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -147.235432\n",
            "---------------------------------------\n",
            "Total T: 895178 Episode Num: 4652 Reward: -225.996633 Avg Reward: -147.625660\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -158.206385\n",
            "---------------------------------------\n",
            "Total T: 900179 Episode Num: 4678 Reward: -1.501896 Avg Reward: -144.671597\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -144.592015\n",
            "---------------------------------------\n",
            "Total T: 905180 Episode Num: 4704 Reward: -117.453095 Avg Reward: -148.051892\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -149.071365\n",
            "---------------------------------------\n",
            "Total T: 910181 Episode Num: 4730 Reward: -225.324986 Avg Reward: -139.755337\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -144.061423\n",
            "---------------------------------------\n",
            "Total T: 915182 Episode Num: 4756 Reward: -221.773164 Avg Reward: -132.934515\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -135.526534\n",
            "---------------------------------------\n",
            "Total T: 920183 Episode Num: 4782 Reward: -124.049409 Avg Reward: -139.583605\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -151.042696\n",
            "---------------------------------------\n",
            "Total T: 925184 Episode Num: 4808 Reward: -235.793666 Avg Reward: -141.186618\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.711903\n",
            "---------------------------------------\n",
            "Total T: 930185 Episode Num: 4834 Reward: -219.421111 Avg Reward: -140.544087\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -144.117899\n",
            "---------------------------------------\n",
            "Total T: 935186 Episode Num: 4860 Reward: -120.611432 Avg Reward: -139.206966\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -130.931024\n",
            "---------------------------------------\n",
            "Total T: 940187 Episode Num: 4886 Reward: -118.256954 Avg Reward: -137.397199\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -137.955534\n",
            "---------------------------------------\n",
            "Total T: 945188 Episode Num: 4912 Reward: -1.268452 Avg Reward: -130.310709\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -138.343811\n",
            "---------------------------------------\n",
            "Total T: 950189 Episode Num: 4938 Reward: -119.253726 Avg Reward: -132.417351\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -130.548809\n",
            "---------------------------------------\n",
            "Total T: 955190 Episode Num: 4964 Reward: -117.151148 Avg Reward: -139.712416\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -140.114430\n",
            "---------------------------------------\n",
            "Total T: 960191 Episode Num: 4990 Reward: -115.949855 Avg Reward: -142.807804\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -143.707542\n",
            "---------------------------------------\n",
            "Total T: 965192 Episode Num: 5016 Reward: -238.995112 Avg Reward: -141.477765\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -141.901166\n",
            "---------------------------------------\n",
            "Total T: 970193 Episode Num: 5042 Reward: -311.902881 Avg Reward: -140.617272\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -157.416156\n",
            "---------------------------------------\n",
            "Total T: 975194 Episode Num: 5068 Reward: -122.772405 Avg Reward: -136.348183\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -159.752974\n",
            "---------------------------------------\n",
            "Total T: 980195 Episode Num: 5094 Reward: -119.105227 Avg Reward: -137.439344\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -131.691998\n",
            "---------------------------------------\n",
            "Total T: 985196 Episode Num: 5120 Reward: -237.345289 Avg Reward: -141.529229\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -139.591452\n",
            "---------------------------------------\n",
            "Total T: 990197 Episode Num: 5146 Reward: -0.995767 Avg Reward: -135.957440\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -135.230520\n",
            "---------------------------------------\n",
            "Total T: 995198 Episode Num: 5172 Reward: -116.415607 Avg Reward: -143.247252\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -150.038637\n",
            "---------------------------------------\n",
            "Total T: 1000199 Episode Num: 5198 Reward: -294.530948 Avg Reward: -142.189497\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -147.002503\n",
            "---------------------------------------\n",
            "Total T: 1005000 Episode Num: 5223 Reward: -256.679327 Avg Reward: -139.415353\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -150.268536\n",
            "---------------------------------------\n",
            "Total T: 1010001 Episode Num: 5249 Reward: -118.518673 Avg Reward: -143.660212\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -134.735483\n",
            "---------------------------------------\n",
            "Total T: 1015002 Episode Num: 5275 Reward: -273.147232 Avg Reward: -140.836778\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -144.227233\n",
            "---------------------------------------\n",
            "Total T: 1020003 Episode Num: 5301 Reward: -119.074925 Avg Reward: -139.697525\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.150052\n",
            "---------------------------------------\n",
            "Total T: 1025004 Episode Num: 5327 Reward: -123.006164 Avg Reward: -137.088181\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -135.453179\n",
            "---------------------------------------\n",
            "Total T: 1030005 Episode Num: 5353 Reward: -119.798884 Avg Reward: -137.571677\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -149.357889\n",
            "---------------------------------------\n",
            "Total T: 1035006 Episode Num: 5379 Reward: -124.218253 Avg Reward: -141.375183\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -155.415427\n",
            "---------------------------------------\n",
            "Total T: 1040007 Episode Num: 5405 Reward: -242.538489 Avg Reward: -138.803440\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.302818\n",
            "---------------------------------------\n",
            "Total T: 1045008 Episode Num: 5431 Reward: -228.758196 Avg Reward: -140.390593\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -139.293389\n",
            "---------------------------------------\n",
            "Total T: 1050009 Episode Num: 5457 Reward: -115.318761 Avg Reward: -148.254895\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -143.069658\n",
            "---------------------------------------\n",
            "Total T: 1055010 Episode Num: 5483 Reward: -233.367867 Avg Reward: -138.233515\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -141.380335\n",
            "---------------------------------------\n",
            "Total T: 1060011 Episode Num: 5509 Reward: -128.735016 Avg Reward: -132.039084\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.742289\n",
            "---------------------------------------\n",
            "Total T: 1065012 Episode Num: 5535 Reward: -123.908873 Avg Reward: -138.353806\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -141.242403\n",
            "---------------------------------------\n",
            "Total T: 1070013 Episode Num: 5561 Reward: -120.634253 Avg Reward: -128.718699\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.269467\n",
            "---------------------------------------\n",
            "Total T: 1075014 Episode Num: 5587 Reward: -121.193475 Avg Reward: -127.902842\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -145.320058\n",
            "---------------------------------------\n",
            "Total T: 1080015 Episode Num: 5613 Reward: -119.488807 Avg Reward: -133.707293\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -145.045586\n",
            "---------------------------------------\n",
            "Total T: 1085016 Episode Num: 5639 Reward: -123.367319 Avg Reward: -131.637888\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -145.034237\n",
            "---------------------------------------\n",
            "Total T: 1090017 Episode Num: 5665 Reward: -124.704078 Avg Reward: -131.764867\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -130.211623\n",
            "---------------------------------------\n",
            "Total T: 1095018 Episode Num: 5691 Reward: -117.716406 Avg Reward: -132.709009\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -147.395454\n",
            "---------------------------------------\n",
            "Total T: 1100019 Episode Num: 5717 Reward: -118.080312 Avg Reward: -144.887663\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -133.079177\n",
            "---------------------------------------\n",
            "Total T: 1105020 Episode Num: 5743 Reward: -117.727859 Avg Reward: -158.029989\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -143.986276\n",
            "---------------------------------------\n",
            "Total T: 1110021 Episode Num: 5769 Reward: -0.255192 Avg Reward: -158.621798\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -136.659802\n",
            "---------------------------------------\n",
            "Total T: 1115022 Episode Num: 5795 Reward: -126.660524 Avg Reward: -161.489052\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -134.053270\n",
            "---------------------------------------\n",
            "Total T: 1120023 Episode Num: 5821 Reward: -122.786710 Avg Reward: -129.562591\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -144.579528\n",
            "---------------------------------------\n",
            "Total T: 1125024 Episode Num: 5847 Reward: -119.323992 Avg Reward: -136.755981\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -141.547305\n",
            "---------------------------------------\n",
            "Total T: 1130025 Episode Num: 5873 Reward: -314.623404 Avg Reward: -142.900173\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -140.822515\n",
            "---------------------------------------\n",
            "Total T: 1135026 Episode Num: 5899 Reward: -234.281437 Avg Reward: -139.381844\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.110992\n",
            "---------------------------------------\n",
            "Total T: 1140027 Episode Num: 5925 Reward: -118.655738 Avg Reward: -140.318123\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -127.351684\n",
            "---------------------------------------\n",
            "Total T: 1145028 Episode Num: 5951 Reward: -118.327396 Avg Reward: -148.000376\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -127.483968\n",
            "---------------------------------------\n",
            "Total T: 1150029 Episode Num: 5977 Reward: -333.131819 Avg Reward: -142.705937\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -145.373243\n",
            "---------------------------------------\n",
            "Total T: 1155030 Episode Num: 6003 Reward: -233.250450 Avg Reward: -150.978314\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -135.509913\n",
            "---------------------------------------\n",
            "Total T: 1160031 Episode Num: 6029 Reward: -124.022789 Avg Reward: -147.272346\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -144.891718\n",
            "---------------------------------------\n",
            "Total T: 1165032 Episode Num: 6055 Reward: -0.210000 Avg Reward: -139.516759\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -132.469518\n",
            "---------------------------------------\n",
            "Total T: 1170033 Episode Num: 6081 Reward: -119.489986 Avg Reward: -139.537724\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -140.090899\n",
            "---------------------------------------\n",
            "Total T: 1175034 Episode Num: 6107 Reward: -127.790835 Avg Reward: -135.008936\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -139.292568\n",
            "---------------------------------------\n",
            "Total T: 1180035 Episode Num: 6133 Reward: -125.048496 Avg Reward: -132.239173\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -139.380858\n",
            "---------------------------------------\n",
            "Total T: 1185036 Episode Num: 6159 Reward: -123.703483 Avg Reward: -134.332520\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -139.372279\n",
            "---------------------------------------\n",
            "Total T: 1190037 Episode Num: 6185 Reward: -121.080102 Avg Reward: -137.113279\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -140.528016\n",
            "---------------------------------------\n",
            "Total T: 1195038 Episode Num: 6211 Reward: -2.891134 Avg Reward: -133.591208\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -134.981073\n",
            "---------------------------------------\n",
            "Total T: 1200039 Episode Num: 6237 Reward: -246.264437 Avg Reward: -142.020023\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -141.302387\n",
            "---------------------------------------\n",
            "Total T: 1205040 Episode Num: 6263 Reward: -232.388703 Avg Reward: -137.107420\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -135.221515\n",
            "---------------------------------------\n",
            "Total T: 1210041 Episode Num: 6289 Reward: -1.268200 Avg Reward: -130.311769\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -137.067026\n",
            "---------------------------------------\n",
            "Total T: 1215042 Episode Num: 6315 Reward: -2.147177 Avg Reward: -133.236337\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -131.755883\n",
            "---------------------------------------\n",
            "Total T: 1220043 Episode Num: 6341 Reward: -227.169642 Avg Reward: -134.442929\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -145.642269\n",
            "---------------------------------------\n",
            "Total T: 1225044 Episode Num: 6367 Reward: -119.643504 Avg Reward: -145.220307\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -156.984704\n",
            "---------------------------------------\n",
            "Total T: 1230045 Episode Num: 6393 Reward: -117.489662 Avg Reward: -148.212140\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.701055\n",
            "---------------------------------------\n",
            "Total T: 1235046 Episode Num: 6419 Reward: -125.987053 Avg Reward: -147.134115\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -145.121798\n",
            "---------------------------------------\n",
            "Total T: 1240047 Episode Num: 6445 Reward: -325.159137 Avg Reward: -138.041477\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -141.817139\n",
            "---------------------------------------\n",
            "Total T: 1245048 Episode Num: 6471 Reward: -287.998349 Avg Reward: -134.274280\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -133.180574\n",
            "---------------------------------------\n",
            "Total T: 1250049 Episode Num: 6497 Reward: -122.526683 Avg Reward: -138.501126\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -162.761224\n",
            "---------------------------------------\n",
            "Total T: 1255050 Episode Num: 6523 Reward: -114.903113 Avg Reward: -143.000298\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -193.901257\n",
            "---------------------------------------\n",
            "Total T: 1260051 Episode Num: 6549 Reward: -223.260529 Avg Reward: -161.790052\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -152.443888\n",
            "---------------------------------------\n",
            "Total T: 1265052 Episode Num: 6575 Reward: -121.093105 Avg Reward: -162.146832\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -153.431744\n",
            "---------------------------------------\n",
            "Total T: 1270053 Episode Num: 6601 Reward: -1.898893 Avg Reward: -160.646359\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -145.818628\n",
            "---------------------------------------\n",
            "Total T: 1275054 Episode Num: 6627 Reward: -127.616881 Avg Reward: -145.079070\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -130.177592\n",
            "---------------------------------------\n",
            "Total T: 1280055 Episode Num: 6653 Reward: -119.759752 Avg Reward: -141.040202\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -137.720431\n",
            "---------------------------------------\n",
            "Total T: 1285056 Episode Num: 6679 Reward: -120.808707 Avg Reward: -137.350840\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -130.563501\n",
            "---------------------------------------\n",
            "Total T: 1290057 Episode Num: 6705 Reward: -123.133641 Avg Reward: -136.781144\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -138.522657\n",
            "---------------------------------------\n",
            "Total T: 1295058 Episode Num: 6731 Reward: -124.124038 Avg Reward: -137.900261\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -139.806148\n",
            "---------------------------------------\n",
            "Total T: 1300059 Episode Num: 6757 Reward: -119.282404 Avg Reward: -141.070187\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -130.553016\n",
            "---------------------------------------\n",
            "Total T: 1305060 Episode Num: 6783 Reward: -114.992490 Avg Reward: -140.069090\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.640130\n",
            "---------------------------------------\n",
            "Total T: 1310061 Episode Num: 6809 Reward: -225.120112 Avg Reward: -138.672216\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -155.273360\n",
            "---------------------------------------\n",
            "Total T: 1315062 Episode Num: 6835 Reward: -9.016827 Avg Reward: -140.382467\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -156.811438\n",
            "---------------------------------------\n",
            "Total T: 1320063 Episode Num: 6861 Reward: -118.359733 Avg Reward: -140.861827\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -143.309605\n",
            "---------------------------------------\n",
            "Total T: 1325064 Episode Num: 6887 Reward: -124.126903 Avg Reward: -136.280656\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -136.136256\n",
            "---------------------------------------\n",
            "Total T: 1330065 Episode Num: 6913 Reward: -5.758314 Avg Reward: -136.240597\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -134.146833\n",
            "---------------------------------------\n",
            "Total T: 1335066 Episode Num: 6939 Reward: -116.378241 Avg Reward: -130.176583\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -135.244723\n",
            "---------------------------------------\n",
            "Total T: 1340067 Episode Num: 6965 Reward: -118.381882 Avg Reward: -130.194604\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -140.871424\n",
            "---------------------------------------\n",
            "Total T: 1345068 Episode Num: 6991 Reward: -3.528429 Avg Reward: -136.263096\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.284551\n",
            "---------------------------------------\n",
            "Total T: 1350069 Episode Num: 7017 Reward: -3.320812 Avg Reward: -142.315446\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -147.236584\n",
            "---------------------------------------\n",
            "Total T: 1355070 Episode Num: 7043 Reward: -119.964098 Avg Reward: -147.080508\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -127.989172\n",
            "---------------------------------------\n",
            "Total T: 1360071 Episode Num: 7069 Reward: -126.448780 Avg Reward: -141.347626\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.295091\n",
            "---------------------------------------\n",
            "Total T: 1365072 Episode Num: 7095 Reward: -117.162245 Avg Reward: -146.644542\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.132387\n",
            "---------------------------------------\n",
            "Total T: 1370073 Episode Num: 7121 Reward: -2.188888 Avg Reward: -147.338304\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -138.512053\n",
            "---------------------------------------\n",
            "Total T: 1375074 Episode Num: 7147 Reward: -115.201205 Avg Reward: -142.739530\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -139.629313\n",
            "---------------------------------------\n",
            "Total T: 1380075 Episode Num: 7173 Reward: -3.737275 Avg Reward: -152.310047\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -140.065301\n",
            "---------------------------------------\n",
            "Total T: 1385076 Episode Num: 7199 Reward: -115.843764 Avg Reward: -145.992758\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -139.393968\n",
            "---------------------------------------\n",
            "Total T: 1390077 Episode Num: 7225 Reward: -120.921669 Avg Reward: -137.737744\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -133.182941\n",
            "---------------------------------------\n",
            "Total T: 1395078 Episode Num: 7251 Reward: -238.514631 Avg Reward: -139.157190\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -152.192266\n",
            "---------------------------------------\n",
            "Total T: 1400079 Episode Num: 7277 Reward: -130.886873 Avg Reward: -135.772394\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.936541\n",
            "---------------------------------------\n",
            "Total T: 1405080 Episode Num: 7303 Reward: -239.478111 Avg Reward: -135.667129\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -151.289521\n",
            "---------------------------------------\n",
            "Total T: 1410081 Episode Num: 7329 Reward: -266.781369 Avg Reward: -136.029830\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.886531\n",
            "---------------------------------------\n",
            "Total T: 1415082 Episode Num: 7355 Reward: -2.990415 Avg Reward: -135.277637\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.723812\n",
            "---------------------------------------\n",
            "Total T: 1420083 Episode Num: 7381 Reward: -2.207871 Avg Reward: -144.346465\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -138.395444\n",
            "---------------------------------------\n",
            "Total T: 1425084 Episode Num: 7407 Reward: -117.908347 Avg Reward: -136.943561\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -137.529653\n",
            "---------------------------------------\n",
            "Total T: 1430085 Episode Num: 7433 Reward: -126.585639 Avg Reward: -142.430018\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -162.732048\n",
            "---------------------------------------\n",
            "Total T: 1435086 Episode Num: 7459 Reward: -253.331293 Avg Reward: -144.581304\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -136.781471\n",
            "---------------------------------------\n",
            "Total T: 1440087 Episode Num: 7485 Reward: -120.269546 Avg Reward: -142.530264\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -145.242278\n",
            "---------------------------------------\n",
            "Total T: 1445088 Episode Num: 7511 Reward: -128.801009 Avg Reward: -143.122244\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -161.735144\n",
            "---------------------------------------\n",
            "Total T: 1450089 Episode Num: 7537 Reward: -118.308465 Avg Reward: -149.402970\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -152.409076\n",
            "---------------------------------------\n",
            "Total T: 1455090 Episode Num: 7563 Reward: -123.162800 Avg Reward: -142.308685\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -135.664697\n",
            "---------------------------------------\n",
            "Total T: 1460091 Episode Num: 7589 Reward: -118.051649 Avg Reward: -140.632557\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -159.550105\n",
            "---------------------------------------\n",
            "Total T: 1465092 Episode Num: 7615 Reward: -3.074613 Avg Reward: -135.813454\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -137.977913\n",
            "---------------------------------------\n",
            "Total T: 1470093 Episode Num: 7641 Reward: -121.823632 Avg Reward: -127.978700\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -150.319443\n",
            "---------------------------------------\n",
            "Total T: 1475094 Episode Num: 7667 Reward: -249.323160 Avg Reward: -128.328129\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -155.077605\n",
            "---------------------------------------\n",
            "Total T: 1480095 Episode Num: 7693 Reward: -126.701352 Avg Reward: -135.377983\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -134.489496\n",
            "---------------------------------------\n",
            "Total T: 1485096 Episode Num: 7719 Reward: -128.646813 Avg Reward: -133.160175\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -149.586295\n",
            "---------------------------------------\n",
            "Total T: 1490097 Episode Num: 7745 Reward: -120.698848 Avg Reward: -140.670775\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -139.585971\n",
            "---------------------------------------\n",
            "Total T: 1495098 Episode Num: 7771 Reward: -121.564944 Avg Reward: -134.054933\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -135.675637\n",
            "---------------------------------------\n",
            "Total T: 1500099 Episode Num: 7797 Reward: -120.105983 Avg Reward: -132.137176\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -153.077972\n",
            "---------------------------------------\n",
            "Total T: 1505100 Episode Num: 7823 Reward: -118.130127 Avg Reward: -136.863645\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -149.745479\n",
            "---------------------------------------\n",
            "Total T: 1510101 Episode Num: 7849 Reward: -119.682368 Avg Reward: -133.121048\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -150.385359\n",
            "---------------------------------------\n",
            "Total T: 1515102 Episode Num: 7875 Reward: -255.943233 Avg Reward: -146.231949\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -137.273012\n",
            "---------------------------------------\n",
            "Total T: 1520103 Episode Num: 7901 Reward: -219.170077 Avg Reward: -148.202775\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -153.945584\n",
            "---------------------------------------\n",
            "Total T: 1525104 Episode Num: 7927 Reward: -231.721693 Avg Reward: -147.858067\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -136.547823\n",
            "---------------------------------------\n",
            "Total T: 1530105 Episode Num: 7953 Reward: -234.265557 Avg Reward: -155.336963\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.032535\n",
            "---------------------------------------\n",
            "Total T: 1535106 Episode Num: 7979 Reward: -228.610588 Avg Reward: -153.957410\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -139.109947\n",
            "---------------------------------------\n",
            "Total T: 1540107 Episode Num: 8005 Reward: -131.620250 Avg Reward: -152.008653\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -139.239005\n",
            "---------------------------------------\n",
            "Total T: 1545108 Episode Num: 8031 Reward: -123.300077 Avg Reward: -155.446276\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -157.480613\n",
            "---------------------------------------\n",
            "Total T: 1550109 Episode Num: 8057 Reward: -261.048667 Avg Reward: -148.656977\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -154.277674\n",
            "---------------------------------------\n",
            "Total T: 1555110 Episode Num: 8083 Reward: -339.945733 Avg Reward: -151.752948\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -154.809177\n",
            "---------------------------------------\n",
            "Total T: 1560111 Episode Num: 8109 Reward: -236.949357 Avg Reward: -149.330599\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -134.731954\n",
            "---------------------------------------\n",
            "Total T: 1565112 Episode Num: 8135 Reward: -237.947583 Avg Reward: -148.338126\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -133.880592\n",
            "---------------------------------------\n",
            "Total T: 1570113 Episode Num: 8161 Reward: -122.613238 Avg Reward: -149.585126\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.781458\n",
            "---------------------------------------\n",
            "Total T: 1575114 Episode Num: 8187 Reward: -125.081675 Avg Reward: -148.154673\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.757203\n",
            "---------------------------------------\n",
            "Total T: 1580115 Episode Num: 8213 Reward: -1.358639 Avg Reward: -144.450979\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -147.527700\n",
            "---------------------------------------\n",
            "Total T: 1585116 Episode Num: 8239 Reward: -2.462633 Avg Reward: -147.731074\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -147.370739\n",
            "---------------------------------------\n",
            "Total T: 1590117 Episode Num: 8265 Reward: -120.091755 Avg Reward: -153.423268\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -136.391106\n",
            "---------------------------------------\n",
            "Total T: 1595118 Episode Num: 8291 Reward: -118.642007 Avg Reward: -151.733494\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -150.566323\n",
            "---------------------------------------\n",
            "Total T: 1600119 Episode Num: 8317 Reward: -299.187155 Avg Reward: -160.200079\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -143.695571\n",
            "---------------------------------------\n",
            "Total T: 1605120 Episode Num: 8343 Reward: -1.723939 Avg Reward: -150.156804\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -150.409813\n",
            "---------------------------------------\n",
            "Total T: 1610121 Episode Num: 8369 Reward: -247.672304 Avg Reward: -147.409176\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -136.760060\n",
            "---------------------------------------\n",
            "Total T: 1615122 Episode Num: 8395 Reward: -237.919727 Avg Reward: -142.276959\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -161.551768\n",
            "---------------------------------------\n",
            "Total T: 1620123 Episode Num: 8421 Reward: -230.179401 Avg Reward: -139.535551\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -132.437865\n",
            "---------------------------------------\n",
            "Total T: 1625124 Episode Num: 8447 Reward: -223.511543 Avg Reward: -150.374079\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -145.876071\n",
            "---------------------------------------\n",
            "Total T: 1630125 Episode Num: 8473 Reward: -123.479317 Avg Reward: -146.604734\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -131.859849\n",
            "---------------------------------------\n",
            "Total T: 1635126 Episode Num: 8499 Reward: -242.178155 Avg Reward: -157.675033\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.860968\n",
            "---------------------------------------\n",
            "Total T: 1640127 Episode Num: 8525 Reward: -4.938456 Avg Reward: -154.976535\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -158.473136\n",
            "---------------------------------------\n",
            "Total T: 1645128 Episode Num: 8551 Reward: -2.777182 Avg Reward: -151.502046\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -162.647379\n",
            "---------------------------------------\n",
            "Total T: 1650129 Episode Num: 8577 Reward: -126.493537 Avg Reward: -154.585673\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -160.761715\n",
            "---------------------------------------\n",
            "Total T: 1655130 Episode Num: 8603 Reward: -127.442311 Avg Reward: -153.217720\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -128.932980\n",
            "---------------------------------------\n",
            "Total T: 1660131 Episode Num: 8629 Reward: -128.991980 Avg Reward: -150.912285\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -135.830302\n",
            "---------------------------------------\n",
            "Total T: 1665132 Episode Num: 8655 Reward: -125.002649 Avg Reward: -154.392627\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -149.940250\n",
            "---------------------------------------\n",
            "Total T: 1670133 Episode Num: 8681 Reward: -116.319288 Avg Reward: -152.028915\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -136.099213\n",
            "---------------------------------------\n",
            "Total T: 1675134 Episode Num: 8707 Reward: -230.577800 Avg Reward: -144.185733\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -123.378917\n",
            "---------------------------------------\n",
            "Total T: 1680135 Episode Num: 8733 Reward: -119.114390 Avg Reward: -147.531593\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -128.190712\n",
            "---------------------------------------\n",
            "Total T: 1685136 Episode Num: 8759 Reward: -119.928341 Avg Reward: -139.285608\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -146.268219\n",
            "---------------------------------------\n",
            "Total T: 1690137 Episode Num: 8785 Reward: -120.236999 Avg Reward: -150.493441\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -134.025674\n",
            "---------------------------------------\n",
            "Total T: 1695138 Episode Num: 8811 Reward: -120.466330 Avg Reward: -147.445051\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -152.592795\n",
            "---------------------------------------\n",
            "Total T: 1700139 Episode Num: 8837 Reward: -117.507726 Avg Reward: -150.005589\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -144.218700\n",
            "---------------------------------------\n",
            "Total T: 1705140 Episode Num: 8863 Reward: -224.692197 Avg Reward: -146.703161\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -138.107940\n",
            "---------------------------------------\n",
            "Total T: 1710141 Episode Num: 8889 Reward: -119.298890 Avg Reward: -139.083972\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -142.510579\n",
            "---------------------------------------\n",
            "Total T: 1715142 Episode Num: 8915 Reward: -1.592856 Avg Reward: -140.643769\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -144.873128\n",
            "---------------------------------------\n",
            "Total T: 1720143 Episode Num: 8941 Reward: -119.380188 Avg Reward: -137.616955\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -128.509377\n",
            "---------------------------------------\n",
            "Total T: 1725144 Episode Num: 8967 Reward: -245.757426 Avg Reward: -143.548673\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -139.525462\n",
            "---------------------------------------\n",
            "Total T: 1730145 Episode Num: 8993 Reward: -117.457249 Avg Reward: -140.184011\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.312799\n",
            "---------------------------------------\n",
            "Total T: 1735146 Episode Num: 9019 Reward: -117.980052 Avg Reward: -150.027347\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -143.034270\n",
            "---------------------------------------\n",
            "Total T: 1740147 Episode Num: 9045 Reward: -0.069645 Avg Reward: -152.973872\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -132.582755\n",
            "---------------------------------------\n",
            "Total T: 1745148 Episode Num: 9071 Reward: -117.560687 Avg Reward: -151.303530\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -154.723774\n",
            "---------------------------------------\n",
            "Total T: 1750149 Episode Num: 9097 Reward: -118.975038 Avg Reward: -154.357222\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -130.323752\n",
            "---------------------------------------\n",
            "Total T: 1755150 Episode Num: 9123 Reward: -248.051831 Avg Reward: -147.188253\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -137.572604\n",
            "---------------------------------------\n",
            "Total T: 1760151 Episode Num: 9149 Reward: -119.531594 Avg Reward: -143.313937\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.400214\n",
            "---------------------------------------\n",
            "Total T: 1765152 Episode Num: 9175 Reward: -122.049742 Avg Reward: -146.784184\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -150.763391\n",
            "---------------------------------------\n",
            "Total T: 1770153 Episode Num: 9201 Reward: -119.329487 Avg Reward: -142.203834\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -131.762617\n",
            "---------------------------------------\n",
            "Total T: 1775154 Episode Num: 9227 Reward: -119.953243 Avg Reward: -135.290437\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -150.459361\n",
            "---------------------------------------\n",
            "Total T: 1780155 Episode Num: 9253 Reward: -1.669123 Avg Reward: -139.784770\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -148.096556\n",
            "---------------------------------------\n",
            "Total T: 1785156 Episode Num: 9279 Reward: -0.462873 Avg Reward: -135.317696\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -159.309545\n",
            "---------------------------------------\n",
            "Total T: 1790157 Episode Num: 9305 Reward: -123.562737 Avg Reward: -140.333892\n",
            "---------------------------------------\n",
            "Evaluation over 100 episodes: -156.288515\n",
            "---------------------------------------\n",
            "Total T: 1792558 Episode Num: 9318 Reward: -266.159252 Avg Reward: -139.600478"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp2UFWtpnpWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "policy.load()\n",
        "\n",
        "for i in range(100):\n",
        "    evaluate_policy(policy, env, render=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZLq4d0anpWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxQ4-QrqnpWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}