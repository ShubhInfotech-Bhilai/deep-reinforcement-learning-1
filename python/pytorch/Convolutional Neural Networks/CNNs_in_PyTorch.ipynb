{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gQEhrWODGxYt"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s3gVLCsfHGms"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_QOKO6R5HfR8"
   },
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5BTbBSIdHSXk",
    "outputId": "f7bae1b2-45fa-43e9-f7e6-1f6fc4f52978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10(\"Cifar/\",train=True,transform=transforms,download=True)\n",
    "test_data = datasets.CIFAR10(\"Cifar/\",train=False,transform=transforms,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nV5VjG0oH1Rk"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data,batch_size=64,num_workers=0,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,batch_size=20,num_workers=0,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "byZt7yo-IYXE",
    "outputId": "5eb81938-6490-423f-f629-0e7df5a272a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RlycwcmGI7U8"
   },
   "outputs": [],
   "source": [
    "images,labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XVMISqBOJzIM",
    "outputId": "0538f536-c3c9-46d1-99b8-b193bb7b3274"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 32, 32])"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "5DxNqhCAIvuM",
    "outputId": "ee22515d-5fd3-4234-dd1c-302f686836db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.25)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # convolutional layer (sees 32x32x3 image tensor)\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        # convolutional layer (sees 16x16x16 tensor)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        # convolutional layer (sees 8x8x32 tensor)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # linear layer (64 * 4 * 4 -> 500)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
    "        # linear layer (500 -> 10)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        # dropout layer (p=0.25)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 2nd hidden layer, with relu activation function\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# create a complete CNN\n",
    "model = Net()\n",
    "print(model)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDjotf0uTUuh"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "30Q8BZMbN4DM",
    "outputId": "555d8a8c-5fea-4e96-cb30-81170b548a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/30 \t Training Loss: 1.017419\n",
      "Epoch 1/30 \t Training Loss: 0.993548\n",
      "Epoch 2/30 \t Training Loss: 0.970909\n",
      "Epoch 3/30 \t Training Loss: 0.944078\n",
      "Epoch 4/30 \t Training Loss: 0.926361\n",
      "Epoch 5/30 \t Training Loss: 0.902615\n",
      "Epoch 6/30 \t Training Loss: 0.885001\n",
      "Epoch 7/30 \t Training Loss: 0.866697\n",
      "Epoch 8/30 \t Training Loss: 0.846309\n",
      "Epoch 9/30 \t Training Loss: 0.827201\n",
      "Epoch 10/30 \t Training Loss: 0.813305\n",
      "Epoch 11/30 \t Training Loss: 0.796012\n",
      "Epoch 12/30 \t Training Loss: 0.777327\n",
      "Epoch 13/30 \t Training Loss: 0.762648\n",
      "Epoch 14/30 \t Training Loss: 0.746774\n",
      "Epoch 15/30 \t Training Loss: 0.729428\n",
      "Epoch 16/30 \t Training Loss: 0.718930\n",
      "Epoch 17/30 \t Training Loss: 0.702704\n",
      "Epoch 18/30 \t Training Loss: 0.686690\n",
      "Epoch 19/30 \t Training Loss: 0.678095\n",
      "Epoch 20/30 \t Training Loss: 0.663241\n",
      "Epoch 21/30 \t Training Loss: 0.648803\n",
      "Epoch 22/30 \t Training Loss: 0.638151\n",
      "Epoch 23/30 \t Training Loss: 0.625551\n",
      "Epoch 24/30 \t Training Loss: 0.613599\n",
      "Epoch 25/30 \t Training Loss: 0.601236\n",
      "Epoch 26/30 \t Training Loss: 0.591148\n",
      "Epoch 27/30 \t Training Loss: 0.573198\n",
      "Epoch 28/30 \t Training Loss: 0.568902\n",
      "Epoch 29/30 \t Training Loss: 0.553698\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if train_on_gpu:\n",
    "  model.cuda()\n",
    "\n",
    "for idx in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    for data, labels in train_loader:\n",
    "        if train_on_gpu:\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss= criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss+=loss.item()*data.size(0)\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    print(\"\\rEpoch {}/{} \\t Training Loss: {:.6f}\".format(idx,n_epochs,train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPb_WtZwZUy_"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rl_PBx3hZbs2"
   },
   "outputs": [],
   "source": [
    "batch_size=20\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "5U-T924YVIMX",
    "outputId": "4761922d-dad6-4024-a490-fc9d571b7143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.730472\n",
      "\n",
      "Test Accuracy of airplane: 84% (843/1000)\n",
      "Test Accuracy of automobile: 88% (883/1000)\n",
      "Test Accuracy of  bird: 71% (718/1000)\n",
      "Test Accuracy of   cat: 55% (556/1000)\n",
      "Test Accuracy of  deer: 60% (600/1000)\n",
      "Test Accuracy of   dog: 67% (671/1000)\n",
      "Test Accuracy of  frog: 77% (770/1000)\n",
      "Test Accuracy of horse: 84% (844/1000)\n",
      "Test Accuracy of  ship: 79% (790/1000)\n",
      "Test Accuracy of truck: 77% (775/1000)\n",
      "\n",
      "Test Accuracy (Overall): 74% (7450/10000)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()\n",
    "for data, target in test_loader:\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    _, pred = torch.max(output, 1)    \n",
    "    \n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CNNs in PyTorch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
